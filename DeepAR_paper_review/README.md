# 논문 리뷰
*Paper link* : [DeepAR : Probabilistic Forecasting with
Autoregressive Recurrent Networks](https://arxiv.org/pdf/1704.04110.pdf﻿)
> 본 논문에서는 LSTM 기반의 seq2seq 구조를 활용하여 여러개의 time series를 global하게 확률적으로 예측하였다. 

# 대본
- 모티베이션:3
  - 이전까지의 예측 모델은 주로 아리마와 지수평활화방법으로 진행되었습니다.
  - 아리마는 이동평균선을 활용한 방식과 자기회기적 모델을 결합한 모델입니다. 
  - 익스포넨셜 스무딩은, 이동평균과 약간 다른 방식으로써 최근의 데이터일 수록 가중치를 주는 방식입니다. 
  - 하지만 수천 수백만의 시계열을 한번에 예측하는데는 옳지 않기에 이런 방식들은 제한적입니다.
- 모티 : 4
  - 그림x,y축 설명
  - 스큐되고, 스케일이 큰 시계열을 예측하는 모델은 어려운 일입니다. 
- 컨트리뷰션 : 5
  - 첫번째는 rnn 구조를 활용한 확률적 예측이라는 점입니다. 
  - 여기서 주요한 것은 값 자체가 아닌, 확률적 예측이라는 점
  - 두번째는 확률적 예측을 통해 모델 정확성을 실험적으로 확인했다는 점입니다. 
  - 특히, 논문에서는 전체 시계열 데이터를 다루는 글로벌 모델임을 강조하고 있습니다. 
- 어드밴티지 : 6
  - 논문에서 말하는 이전 연구와는 다른 4가지 이점을 말하고있는데요
  - 피쳐 엔지니어링을 최소화 할수 있다는 점입니다. 
    - 인공신경망이 학습을 더 잘할 수 있도록 특징을 확정짓고 두드러지게 만들어주는 작업인데요.
    - 이러한 작업을 최소화 했다고 합니다.
  - 확률적 예측
    - 분포를 제시함으로써 신뢰도를 up
  - 데이터 없는 새로운 아이템들에 대한 예측이 가능하다고 합니다. 
    - 확률적 예측이기에 가능하다고 생각합니다.
  - 가우시안 노이즈를 가정하고 있지 않다는 점입니다. 
    - 통계적으로 적절하게 바꿀 수 있다고 말하고 있음
- 이전 연구 : 8
  - 하나의 개별 시계열에 대한 예측은 앞서 말씀드린 아리마, 지수평활이 있습니다. 
  - 수요 예측 분야에서는 데이터 전처리가 큰 의미가 없는 경우가 많다고 합니다.
    - 그이유는 결측치도 많고, 변동성이 크기 때문입니다.
    - 따라서 분포와 관련된 연구가 많이 진행되어져 왔습니다.
  - 또 여러 시계열간에 서로의 정보를 공유한 예측도 진행되어져 왔습니다. 
    - 하지만 이는 실제에선 잘 통하지 않기 때문에 
    - 매트릭스 팩토라이제이션이라던지, 베이지안 방법들로 연구를 진행했다고합니다. 
- 모델 : 노테이션 10
  - 모델에 관해 설명드리기 앞서 간단한 노테이션을 정의하고 가겠습니다. 
  - 시리즈 z는 다음과 같이 정의합니다. 
  - 여기서 z의 인덱스인 i는 시계열의 넘버 즉 i번째 아이템에 대한 시계열이고, 두번째 1부터 라지T 인덱스는 시간입니다. 여기서 t_0는 예측을 실시하고자 하는 현재시점을 말합니다. 주의할점은 전체 렝스는 t_0+T라는 점입니다. 
  - 코베리에이츠는 1부터 예측완료시점인 T까지 모든지점에 대해 알려진 변수입니다. 예를들면 날씨나 계절, 등이 있습니다. 
- 모델 : 아키텍쳐 11    
  - 모델의 기본 아키텍쳐는 다음과 같습니다. 
  - RNN기반의 Seq2Seq 형태를 띄고 있고, 모델의 목적은 인풋값인 과거 1부터 t_0까지의 과거 시리즈와 코베리에이츠로부터 미래의 확률분포를 얻는 것입니다. 
  - 논문에서는 여러 데이터셋으로 실험을 했는데, 레이어는 지금 보시는것처럼 3개, 노드는 40~120의 데이터로 실험했고습니다. 
  - 가운데 네트워크 레이어는 LSTM 셀로 이루어져있고, 마지막단은 likelihood 함수를 통과하게 됩니다. 
  - 여기서 세타는 해당 라이클리 함수에서 사용하는 파라미터입니다. 
  - 데이터마다 다른 종류의 라이클리함수를 사용했기 때문인데요, 
  - 자세한건 뒤에서 설명드리겠습니다. 
- 모델 : 라이클리훗 모델 12
  - 논문에서는 크게 두종류의 라이클리를 사용했습니다. 
  - 데이터가 비율이나 빈도처럼 실수값을 가지는 데이터는 가우시안을 사용했고, 
  - 나머지 모든 양의 셀수 있는 데이터로 나온 것들은 음이항분포를 사용했습니다. 
  - 가우시안은 흔히 아시는 정규분포라고 생각하시면 됩니다. 
  - 음이항분포는 파라미터가 두개이고, 이중 뒤의 파라미터인 알파는 보통 분포의 모양을 변형시키기에 쉐입파라미터라고도 합니다. 
- 모델 : 라이클리13
  - 일단 이항분포는 확률 P인 시행을 n번시행하면 몇번 성공할 것인가에 대한 문제입니다. 
  - 평균은 np겠고요. - 동전얘기
  - 특히, 포아송 분포는 이항분포의 한 특별한 케이스라고 볼 수 있습니다.
- 모델 : 라이클리 13
  - 반면 음이항 분포는 이항분포와는 반대로 mu만큼의 사건을 성공시키려면 몇번 시행해야하는가 에 대한 문제입니다. 
  - 예시 들어주기
- 모델 : 라이클리 13
  - 리테일에 잘 맞는다고 연구가 되어왔습니다.
- 트레이닝 14
  - 그림에서 세로선은 현재 예측하고자 하는 시점입니다. 
  - 인풋으로는 데이터의 시작인 1부터 현재인 t제로 까지의 데이터
  - 그리고 코베리에이츠는 1부터 T까지의 전체데이터를 학습시키게됩니다.
  - 그런데 다학습하는것이 아님니다.
- 트레이닝15-18
  - 이만큼의 범위가 예측하고자 하는 라지 T만큼의 범위인데, 
  - 그 라지 티만큼의 범위를 갖는 '윈도우'라는 것을 만들고 그 윈도우를 랜덤으로 추출하면서 학습시키게 됩니다.
  - 또 이렇게 예측하고자 하는 범위보다 가진 데이터가 적을 때에는, 앞부분을 다 영값으로 패딩한 뒤 학습을 시킵니다. 
- 모델 : 트레이닝 19
  - 학습을 할때에는 라이클리후드를 통해 나온 확률변수를 최대로 만들도록 학습을 시키고, 맥시멈 라이클리 후드 값을 계산을 하게 됩니다. 
  - 그 이유는, 모델이 전단계에서 네트워크를 통해 제시한 만든 파라미터로 만든 분포가 다음단계에서의 그라운드 트루스인 확률 변수를 뽑을 가능성이 더 높다는 것, 즉 분포를 정확히 제시하고 있는 중이라는 뜻입니다. 
- 스케일 핸들링 : 20
  - 논문에서는 이런 샘플링 스킴 말고도, 트레이닝 방식으로 스케일 핸들링 방법을 제시하고 있습니다. 
  - 첫째는 선형성을 만족하지 않는 네트워크에서 문제가 발생할 수 있기 때문에 네트워크 레이어 앞에서 확률변수에 스케일 팩터를 나누고 네트워크 통과 후 다시 곱해주는 형식으로 스케일링을 했다고 합니다. 
  - 스케일 팩터의 값은 다음과 같습니다. 
  - 오타 수정
  - 또, 이 스케일값 vi에 따라 시계열에서 윈도우를 더 많이 뽑습니다. 
  - 즉, 많이 팔리는 물건이 존재하는 시계열에서 윈도우를 더 많이 추출하는 방식입니다. 
- 예측 : 21-22
  - 그래서 이렇게 훈련된 네트워크의 정보를 디코더 부분으로 넘겨주게 됩니다. 
- 예측 : 23-24
  - 그렇게 넘어온 네트워크의 가중치에서 만든 라이클리 함수의 파라미터로 분포를 만들고 그 분포에서 추출한 샘플을 다시 다음 노드의 인풋으로 넣는 작업을 반복하게 됩니다. 
  - 그렇게 한바퀴 돈 시퀀스를 여기서는 트레이스라고 표현하는데, 그러한 트레이스를 여러번 반복함으로써 음영과 같은 분포를 만들게 됩니다. 
- 실험 25
  - 이러한 데이터셋들을 사용했습니다. 
- 실험 26
  - 아마존에서 보유한 실제 데이터인 ec데이터로 실험은 해본 결과 다음처럼 예측을 잘 수행했단 것을 볼 수 있습니다. 
  - y축보면 첫번째 데이터는 수요가 많은 아이템에 대한 시계열입니다. 
  - 영역의 p50 그러니깐 메디안 값을 나타내는 선이 보이는데, 첫번째는 예측굳
  - 나머지는 다 0에 근처함. 이는 판매량이 거의 없기 때문임
- 실험28
  - 다음은 여러 모델에 대해서 rho-리스크라는 메트릭으로 성능을 판별한 모습입니다.
  - 로 리스크는 로-퀀타일 로스의 값들을 노말라이즈한 값입니다. 
  - 표에서 L과 S는 예측 이후의 특정 두 시점입니다. 
  - 그 두 시점 사이에서 샘플링된 모든 확률변수들의 합을 span한다고 하는데, 
  - 그렇게 스팬된 값의 5분위수, 9분위 수 지점의 분포들을 그리고, 그 분포들과 실제 데이터가 얼마나 떨어져 있는지를 계산한 값으로 생각하면 됩니다. 
- 실험29 비교
  - 파란선은 과거 저자들이 만든 issm이라는 모델인데, 크리스마스에 대한 정보를 정확히 예측
  - 불확실성 얘기
  - 빨간색은 애초에 가정, 파랑색은 아님
- 결론
  - 방법적 측면 : 확률적 예측을 통해서 예측 정확성을 향상시켰음을 강조
  - 모델적 측면 : 
    - 시계열의 개별 예측이 아닌, 글로벌한 예측을 수행했고, 
    - 리스케일링, 
    - 계절성이나 불확실성에 대한 성장도 학습을 할 수 있었다고 얘기하며 마치고 있습니다